{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokenization:\n",
      "['NLTK', 'is', 'a', 'leading', 'platform', 'for', 'building', 'Python', 'programs', 'to', 'work', 'with', 'human', 'language', 'data', '.']\n",
      "\n",
      "Sentence Tokenization:\n",
      "['NLTK is a leading platform for building Python programs to work with human language data.']\n",
      "Filtered Words after Stopword Removal:\n",
      "['NLTK', 'leading', 'platform', 'building', 'Python', 'programs', 'work', 'human', 'language', 'data', '.']\n",
      "Stemmed Words:\n",
      "['nltk', 'lead', 'platform', 'build', 'python', 'program', 'work', 'human', 'languag', 'data', '.']\n",
      "Lemmatized Words: ['NLTK', 'is', 'a', 'leading', 'platform', 'for', 'building', 'Python', 'program', 'to', 'work', 'with', 'human', 'language', 'data', '.']\n",
      "POS Tags: [('NLTK', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('leading', 'VBG'), ('platform', 'NN'), ('for', 'IN'), ('building', 'VBG'), ('Python', 'NNP'), ('programs', 'NNS'), ('to', 'TO'), ('work', 'VB'), ('with', 'IN'), ('human', 'JJ'), ('language', 'NN'), ('data', 'NNS'), ('.', '.')]\n",
      "NER Tags: (S\n",
      "  (ORGANIZATION NLTK/NNP)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  leading/VBG\n",
      "  platform/NN\n",
      "  for/IN\n",
      "  building/VBG\n",
      "  (PERSON Python/NNP)\n",
      "  programs/NNS\n",
      "  to/TO\n",
      "  work/VB\n",
      "  with/IN\n",
      "  human/JJ\n",
      "  language/NN\n",
      "  data/NNS\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ne_chunk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "text = \"\"\"NLTK is a leading platform for building Python programs to work with human language data.\"\"\"\n",
    "words = word_tokenize(text, preserve_line=True)\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "print(\"Word Tokenization:\")\n",
    "print(words)\n",
    "\n",
    "print(\"\\nSentence Tokenization:\")\n",
    "print(sentences)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "print(\"Filtered Words after Stopword Removal:\")\n",
    "print(filtered_words)\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "stemmed_words = [porter_stemmer.stem(word) for word in filtered_words]\n",
    "\n",
    "print(\"Stemmed Words:\")\n",
    "print(stemmed_words)\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "print(\"Lemmatized Words:\", lemmatized_words)\n",
    "\n",
    "# POS tagging\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "print(\"POS Tags:\", pos_tags)\n",
    "\n",
    "# NER\n",
    "ner_tags = ne_chunk(pos_tags)\n",
    "print(\"NER Tags:\", ner_tags)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
